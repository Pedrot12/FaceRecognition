# -*- coding: utf-8 -*-
"""Reconhecimento_facial.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/github/Pedrot12/Face-Recognition/blob/main/Reconhecimento_facial.ipynb

#OpenCV

## Carregamento da base de dados
"""

from PIL import Image
import cv2
import numpy as np
from google.colab.patches import cv2_imshow
from google.colab import drive
drive.mount('/content/drive')
!unzip '/content/drive/MyDrive/Visão Computacional Guia Completo-20221226T193816Z-001.zip'

import zipfile
path = '/content/Visão Computacional Guia Completo/Datasets/yalefaces.zip'
zip_object = zipfile.ZipFile(file=path, mode='r')
zip_object.extractall('./')
zip_object.close()

"""## Pré-processamento das imagens"""

import os
print(os.listdir('/content/yalefaces/train'))

def get_image_data():
  paths = [os.path.join('/content/yalefaces/train',f)for f in os.listdir('/content/yalefaces/train')] #junta diretório com o nome do arquivo
  print(paths)
  faces  = []
  ids = []
  for path in paths:
    image = Image.open(path).convert('L') #converte para a escala de cinza
    image_np = np.array(image,'uint8')
    id = int(os.path.split(path)[1].split('.')[0].replace('subject',""))
    ids.append(id)
    faces.append(image_np)
  return np.array(ids),faces

get_image_data()

ids, faces = get_image_data()

"""## Treinamento do LBPH"""

lbph_classifier = cv2.face.LBPHFaceRecognizer_create(radius=4,neighbors=14,grid_x=9,grid_y=9)
lbph_classifier.train(faces,ids)
lbph_classifier.write('lbph_classifier.yml')

"""## Reconhecimento de faces"""

lbph_face_classifier = cv2.face.LBPHFaceRecognizer_create()
lbph_face_classifier.read('/content/lbph_classifier.yml')

image_test = '/content/yalefaces/test/subject10.sad.gif'

image =Image.open(image_test).convert('L')
image_np = np.array(image,'uint8')

predict = lbph_face_classifier.predict(image_np)
predict

expected_output = int(os.path.split(image_test)[1].split('.')[0].replace('subject',''))
expected_output

cv2.putText(image_np, 'Pred: '+str(predict[0]),(10,30),cv2.FONT_HERSHEY_COMPLEX_SMALL,1,(0,255,0))
cv2.putText(image_np, 'Exp: '+str(expected_output),(10,50),cv2.FONT_HERSHEY_COMPLEX_SMALL,1,(0,255,0))
cv2_imshow(image_np)

"""## Avaliacao do classificador"""

paths = [os.path.join('/content/yalefaces/test',f)for f in os.listdir('/content/yalefaces/test')]
predicts =[]
exp_outputs = []
for path in paths:
  image =Image.open(path).convert('L')
  image_np = np.array(image,'uint8')
  predict, _=lbph_face_classifier.predict(image_np)
  exp_output = int(os.path.split(path)[1].split('.')[0].replace('subject',''))
  predicts.append(predict)
  exp_outputs.append(exp_output)

predicts =np.array(predicts)
exp_outputs = np.array(exp_outputs)

predicts

exp_outputs

from sklearn.metrics import accuracy_score
accuracy_score(exp_outputs,predicts)

from sklearn.metrics import confusion_matrix
cm = confusion_matrix(exp_outputs,predicts)
cm

import seaborn
seaborn.heatmap(cm,annot=True);

"""# Dlib"""

import dlib

"""## Detecção de pontos faciais"""

detector_face = dlib.get_frontal_face_detector()
detector_points = dlib.shape_predictor('/content/Visão Computacional Guia Completo/Weights/shape_predictor_68_face_landmarks.dat')

image = cv2.imread('/content/Visão Computacional Guia Completo/Images/people2.jpg')
detections = detector_face(image,1)
for face in detections:
  points = detector_points(image,face)
  for point in points.parts():
    cv2.circle(image,(point.x,point.y),2,(0,255,0),1)

  l,t,r,b = face.left(), face.top(),face.right(),face.bottom()
  cv2.rectangle(image,(l,t),(r,b),(0,255,255),2)
cv2_imshow(image)

"""## Detecção de descritores faciais"""

detector_face = dlib.get_frontal_face_detector()
detector_points = dlib.shape_predictor('/content/Visão Computacional Guia Completo/Weights/shape_predictor_68_face_landmarks.dat')
descritor_facial_extrator = dlib.face_recognition_model_v1('/content/Visão Computacional Guia Completo/Weights/dlib_face_recognition_resnet_model_v1.dat')

index = {}
idx = 0
descritors_facial = None
paths=[os.path.join('/content/yalefaces/train',f)for f in os.listdir('/content/yalefaces/train')]
for path in paths:
  image = Image.open(path).convert('RGB') #converte para o formato RGB
  image_np = np.array(image,'uint8')
  detections = detector_face(image_np,1)
  for face in detections:
    l,t,r,b = face.left(), face.top(),face.right(),face.bottom()
    cv2.rectangle(image_np,(l,t),(r,b),(0,0,255),2)

    points = detector_points(image_np,face)
    for point in points.parts():
      cv2.circle(image_np,(point.x,point.y),2,(0,255,0),1)

    descritor_facial = descritor_facial_extrator.compute_face_descriptor(image_np,points)
    descritor_facial = np.asarray([f for f in descritor_facial],dtype=np.float64)
    descritor_facial =descritor_facial[np.newaxis, :]
    if descritors_facial is None:
      descritors_facial = descritor_facial
    else:
      descritors_facial = np.concatenate((descritors_facial,descritor_facial),axis=0)



    index[idx]=path
    idx+=1
  cv2_imshow(image_np)

len(index)

"""## Cálculo de distância entre faces

"""

np.linalg.norm(descritors_facial[131]-descritors_facial[131])
# np.linalg.norm(descritors_facial[131]-descritors_facial[130])

np.linalg.norm(descritors_facial[0]-descritors_facial,axis=1)

np.argmin(np.linalg.norm(descritors_facial[0]-descritors_facial[1:],axis=1))

np.linalg.norm(descritors_facial[0]-descritors_facial[1:],axis=1)[94]

# index[0]
index[95]

"""## Reconhecimento facial com Dlib"""

from unicodedata import name
acurracy = 0.5
predicts=[]
exp_output = []
paths = [os.path.join('/content/yalefaces/test',f)for f in os.listdir('/content/yalefaces/test')]
for path in paths:
  image = Image.open(path).convert('RGB')
  print(path)
  image_np = np.array(image,'uint8')
  dections = detector_face(image_np,1)
  for face in dections:
    points = detector_points(image_np,face)
    descritor_facial = descritor_facial_extrator.compute_face_descriptor(image_np,points)
    descritor_facial = [f for f in descritor_facial]
    descritor_facial = np.asarray(descritor_facial, dtype=np.float64)
    descritor_facial =descritor_facial[np.newaxis, :]

    dists = np.linalg.norm(descritor_facial - descritors_facial,axis=1)
    idx_min = np.argmin(dists)
    dist_min = dists[idx_min]
    if dist_min <= acurracy:
      name_prediction = int(os.path.split(index[idx_min])[1].split('.')[0].replace('subject',''))
    else:
      name_prediction = 'Face não indentificada'

    name_real = int(os.path.split(path)[1].split('.')[0].replace('subject',''))

    predicts.append(name_prediction)
    exp_output.append(name_real)

    cv2.putText(image_np,'Pred: '+ str(name_prediction),(10,30),cv2.FONT_HERSHEY_COMPLEX_SMALL,1,(0,255,0))
    cv2.putText(image_np,'Exp: '+ str(name_real),(10,50),cv2.FONT_HERSHEY_COMPLEX_SMALL,1,(0,255,0))

  cv2_imshow(image_np)

predicts = np.array(predicts)
exp_output = np.array(exp_output)

predicts

exp_output

from sklearn.metrics import accuracy_score
accuracy_score(exp_output,predicts)